{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97dc434c",
   "metadata": {},
   "source": [
    "<center><h1>Management and Analysis of Physics Dataset (MOD. B) </h1></center>\n",
    "<center><h2> Project 5 - Streaming processing of cosmic rays using Drift Tubes detectors</h2></center>\n",
    "<center><h2>Group 2305</h2></center>\n",
    "\n",
    "<center><style>\n",
    "    table {font-size: 24px;}\n",
    "</style></center>\n",
    "\n",
    "| Last Name        | First Name         |Student ID|\n",
    "|:----------------:|:------------------:|:--------------:|\n",
    "| Bertinelli       | Gabriele           |1219907 (tri)   |\n",
    "| Bhatti           | Roben              |2091187         |\n",
    "| Bonato           | Diego              |2091250         |\n",
    "| Cacciola         | Martina            |2097476         |\n",
    "\n",
    "<left><h2> Part 4 - Metrics analysis</h2></left>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1171fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n",
    "import json\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd783df",
   "metadata": {},
   "source": [
    "## Best configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a34c5864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batchId</th>\n",
       "      <th>numInputRows</th>\n",
       "      <th>inputRowsPerSecond</th>\n",
       "      <th>processedRowsPerSecond</th>\n",
       "      <th>durationMs</th>\n",
       "      <th>Executors</th>\n",
       "      <th>Cores</th>\n",
       "      <th>ShufflePartitions</th>\n",
       "      <th>Arrow</th>\n",
       "      <th>Workers</th>\n",
       "      <th>KafkaPartitions</th>\n",
       "      <th>Batches</th>\n",
       "      <th>Trigger</th>\n",
       "      <th>msgrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.751</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28000</td>\n",
       "      <td>880.669309</td>\n",
       "      <td>1421.608448</td>\n",
       "      <td>19.695</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.421681e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18000</td>\n",
       "      <td>913.751967</td>\n",
       "      <td>1643.385374</td>\n",
       "      <td>10.953</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.643385e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>912.741877</td>\n",
       "      <td>1282.873637</td>\n",
       "      <td>7.795</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.282874e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7000</td>\n",
       "      <td>897.666068</td>\n",
       "      <td>1013.024602</td>\n",
       "      <td>6.910</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.013025e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>307</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1881.821603</td>\n",
       "      <td>2.657</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.881822e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>308</td>\n",
       "      <td>4000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>1674.340728</td>\n",
       "      <td>2.389</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.674341e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>309</td>\n",
       "      <td>5000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>2000.800320</td>\n",
       "      <td>2.499</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>2.000800e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>310</td>\n",
       "      <td>4650</td>\n",
       "      <td>930.000000</td>\n",
       "      <td>1746.806912</td>\n",
       "      <td>2.662</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.746807e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>311</td>\n",
       "      <td>1350</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>453.629032</td>\n",
       "      <td>2.976</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>4.536290e+05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     batchId  numInputRows  inputRowsPerSecond  processedRowsPerSecond  \\\n",
       "0          0             0            0.000000                0.000000   \n",
       "1          1         28000          880.669309             1421.608448   \n",
       "2          2         18000          913.751967             1643.385374   \n",
       "3          3         10000          912.741877             1282.873637   \n",
       "4          4          7000          897.666068             1013.024602   \n",
       "..       ...           ...                 ...                     ...   \n",
       "307      307          5000         1000.000000             1881.821603   \n",
       "308      308          4000          800.000000             1674.340728   \n",
       "309      309          5000         1000.000000             2000.800320   \n",
       "310      310          4650          930.000000             1746.806912   \n",
       "311      311          1350          270.000000              453.629032   \n",
       "\n",
       "     durationMs  Executors  Cores  ShufflePartitions Arrow  Workers  \\\n",
       "0        31.751         10      1                 10    aT        3   \n",
       "1        19.695         10      1                 10    aT        3   \n",
       "2        10.953         10      1                 10    aT        3   \n",
       "3         7.795         10      1                 10    aT        3   \n",
       "4         6.910         10      1                 10    aT        3   \n",
       "..          ...        ...    ...                ...   ...      ...   \n",
       "307       2.657         10      1                 10    aT        3   \n",
       "308       2.389         10      1                 10    aT        3   \n",
       "309       2.499         10      1                 10    aT        3   \n",
       "310       2.662         10      1                 10    aT        3   \n",
       "311       2.976         10      1                 10    aT        3   \n",
       "\n",
       "     KafkaPartitions  Batches  Trigger       msgrate  \n",
       "0                 10     1000        5  0.000000e+00  \n",
       "1                 10     1000        5  1.421681e+06  \n",
       "2                 10     1000        5  1.643385e+06  \n",
       "3                 10     1000        5  1.282874e+06  \n",
       "4                 10     1000        5  1.013025e+06  \n",
       "..               ...      ...      ...           ...  \n",
       "307               10     1000        5  1.881822e+06  \n",
       "308               10     1000        5  1.674341e+06  \n",
       "309               10     1000        5  2.000800e+06  \n",
       "310               10     1000        5  1.746807e+06  \n",
       "311               10     1000        5  4.536290e+05  \n",
       "\n",
       "[312 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the target filename\n",
    "target_filename = '10ex_1core_10sp_aT_3w_10kp.json'\n",
    "\n",
    "df1_list = []\n",
    "\n",
    "for filename in os.listdir('./metriche/'):\n",
    "    if filename == target_filename:\n",
    "        # Retrieve the file path\n",
    "        file_path = os.path.join('./metriche/', filename)\n",
    "\n",
    "        # Extract the parameters from the filename\n",
    "        params = filename.split('.')[0].split('_')\n",
    "        ex = int(params[0].replace('ex', ''))\n",
    "        core = int(params[1].replace('core', ''))\n",
    "        sp = int(params[2].replace('sp', ''))\n",
    "        arrow = params[3]\n",
    "        w = int(re.findall(r'\\d+', params[4])[0])\n",
    "        kp = int(re.findall(r'\\d+', params[5])[0]) if len(params) > 5 and params[5].endswith('kp') else None\n",
    "        batch = int(re.findall(r'\\d+', params[6])[0]) if len(params) > 6 and params[6].startswith('batch') else 1000\n",
    "        secProcTime = int(re.findall(r'\\d+', params[-1])[0]) if params[-1].endswith('secProcTime') else 5\n",
    "\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1['Executors'] = ex\n",
    "        df1['Cores'] = core\n",
    "        df1['ShufflePartitions'] = sp\n",
    "        df1['Arrow'] = arrow\n",
    "        df1['Workers'] = w\n",
    "        df1['KafkaPartitions'] = kp\n",
    "        df1['Batches'] = batch\n",
    "        df1['Trigger'] = secProcTime\n",
    "\n",
    "        batchId = []\n",
    "        numInputRows = []\n",
    "        inputRowsPerSecond = []\n",
    "        processedRowsPerSecond = []\n",
    "        durationMs = []\n",
    "        numOutputRows = []\n",
    "\n",
    "        for item in data:\n",
    "            try:\n",
    "                batchId.append(item[\"batchId\"])\n",
    "                numInputRows.append(item[\"numInputRows\"])\n",
    "                inputRowsPerSecond.append(item[\"inputRowsPerSecond\"])\n",
    "                processedRowsPerSecond.append(item[\"processedRowsPerSecond\"])\n",
    "                duration_Ms = item[\"durationMs\"][\"triggerExecution\"] / 1000  # convert from ms to s\n",
    "                durationMs.append(duration_Ms)\n",
    "                numOutputRows.append(item[\"sink\"][\"numOutputRows\"])\n",
    "            except Exception as e:\n",
    "                batchID_debug = item[\"batchId\"]\n",
    "                print(f\"Error encountered in batch {batchID_debug}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Check and align the lengths of the arrays\n",
    "        length = max(len(batchId), len(numInputRows), len(inputRowsPerSecond),\n",
    "                     len(processedRowsPerSecond), len(durationMs), len(numOutputRows))\n",
    "\n",
    "        batchId += [np.nan] * (length - len(batchId))\n",
    "        numInputRows += [np.nan] * (length - len(numInputRows))\n",
    "        inputRowsPerSecond += [np.nan] * (length - len(inputRowsPerSecond))\n",
    "        processedRowsPerSecond += [np.nan] * (length - len(processedRowsPerSecond))\n",
    "        durationMs += [np.nan] * (length - len(durationMs))\n",
    "        numOutputRows += [np.nan] * (length - len(numOutputRows))\n",
    "\n",
    "        # Add arrays as columns to the DataFrame\n",
    "        df1['batchId'] = batchId\n",
    "        df1['numInputRows'] = numInputRows\n",
    "        df1['inputRowsPerSecond'] = inputRowsPerSecond\n",
    "        df1['processedRowsPerSecond'] = processedRowsPerSecond\n",
    "        df1['durationMs'] = durationMs\n",
    "        df1['numOutputRows'] = numOutputRows\n",
    "\n",
    "        # Compute message rate\n",
    "        df1['msgrate'] = df1['numInputRows'] / (df1['durationMs'] / 1000)  # Convert duration to seconds\n",
    "\n",
    "        # Drop the unnecessary columns\n",
    "        drop_columns = ['id', 'runId', 'name', 'timestamp', 'stateOperators', 'sources', 'sink', 'numOutputRows']\n",
    "        df1 = df1.drop(drop_columns, axis=1, errors='ignore')\n",
    "\n",
    "        # Append DataFrame to the list\n",
    "        df1_list.append(df1)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "df1 = pd.concat(df1_list, ignore_index=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136eb3c3",
   "metadata": {},
   "source": [
    "## Worst configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82d291e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batchId</th>\n",
       "      <th>numInputRows</th>\n",
       "      <th>inputRowsPerSecond</th>\n",
       "      <th>processedRowsPerSecond</th>\n",
       "      <th>durationMs</th>\n",
       "      <th>Executors</th>\n",
       "      <th>Cores</th>\n",
       "      <th>ShufflePartitions</th>\n",
       "      <th>Arrow</th>\n",
       "      <th>Workers</th>\n",
       "      <th>KafkaPartitions</th>\n",
       "      <th>Batches</th>\n",
       "      <th>Trigger</th>\n",
       "      <th>msgrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.926080</td>\n",
       "      <td>39.703</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>6.926429e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>62515</td>\n",
       "      <td>1571.557857</td>\n",
       "      <td>3216.785016</td>\n",
       "      <td>19.433</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>3.216951e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>30506</td>\n",
       "      <td>1569.319409</td>\n",
       "      <td>2212.343172</td>\n",
       "      <td>13.789</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>2.212343e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22459</td>\n",
       "      <td>1628.407773</td>\n",
       "      <td>1716.392816</td>\n",
       "      <td>13.085</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.716393e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>21248</td>\n",
       "      <td>1623.471883</td>\n",
       "      <td>1866.479269</td>\n",
       "      <td>11.384</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.866479e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>11676</td>\n",
       "      <td>1490.045942</td>\n",
       "      <td>1731.060044</td>\n",
       "      <td>6.745</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.731060e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>109</td>\n",
       "      <td>9711</td>\n",
       "      <td>1439.093065</td>\n",
       "      <td>1401.703233</td>\n",
       "      <td>6.928</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.401703e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>110</td>\n",
       "      <td>10560</td>\n",
       "      <td>1523.809524</td>\n",
       "      <td>1537.117904</td>\n",
       "      <td>6.870</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.537118e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>10274</td>\n",
       "      <td>1494.834861</td>\n",
       "      <td>1376.289350</td>\n",
       "      <td>7.465</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.376289e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>112</td>\n",
       "      <td>12342</td>\n",
       "      <td>1652.651312</td>\n",
       "      <td>1730.995792</td>\n",
       "      <td>7.130</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>aT</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.730996e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     batchId  numInputRows  inputRowsPerSecond  processedRowsPerSecond  \\\n",
       "0          0           275            0.000000                6.926080   \n",
       "1          1         62515         1571.557857             3216.785016   \n",
       "2          2         30506         1569.319409             2212.343172   \n",
       "3          3         22459         1628.407773             1716.392816   \n",
       "4          4         21248         1623.471883             1866.479269   \n",
       "..       ...           ...                 ...                     ...   \n",
       "108      108         11676         1490.045942             1731.060044   \n",
       "109      109          9711         1439.093065             1401.703233   \n",
       "110      110         10560         1523.809524             1537.117904   \n",
       "111      111         10274         1494.834861             1376.289350   \n",
       "112      112         12342         1652.651312             1730.995792   \n",
       "\n",
       "     durationMs  Executors  Cores  ShufflePartitions Arrow  Workers  \\\n",
       "0        39.703         10      1                 10    aT        3   \n",
       "1        19.433         10      1                 10    aT        3   \n",
       "2        13.789         10      1                 10    aT        3   \n",
       "3        13.085         10      1                 10    aT        3   \n",
       "4        11.384         10      1                 10    aT        3   \n",
       "..          ...        ...    ...                ...   ...      ...   \n",
       "108       6.745         10      1                 10    aT        3   \n",
       "109       6.928         10      1                 10    aT        3   \n",
       "110       6.870         10      1                 10    aT        3   \n",
       "111       7.465         10      1                 10    aT        3   \n",
       "112       7.130         10      1                 10    aT        3   \n",
       "\n",
       "     KafkaPartitions  Batches  Trigger       msgrate  \n",
       "0                200     1000        5  6.926429e+03  \n",
       "1                200     1000        5  3.216951e+06  \n",
       "2                200     1000        5  2.212343e+06  \n",
       "3                200     1000        5  1.716393e+06  \n",
       "4                200     1000        5  1.866479e+06  \n",
       "..               ...      ...      ...           ...  \n",
       "108              200     1000        5  1.731060e+06  \n",
       "109              200     1000        5  1.401703e+06  \n",
       "110              200     1000        5  1.537118e+06  \n",
       "111              200     1000        5  1.376289e+06  \n",
       "112              200     1000        5  1.730996e+06  \n",
       "\n",
       "[113 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the target filename\n",
    "target_filename = '10ex_1core_10sp_aT_3w_200kp_5000batch_5secProcTime.json'\n",
    "\n",
    "df2_list = []\n",
    "\n",
    "for filename in os.listdir('./metriche/'):\n",
    "    if filename == target_filename:\n",
    "        # Retrieve the file path\n",
    "        file_path = os.path.join('./metriche/', filename)\n",
    "\n",
    "        # Extract the parameters from the filename\n",
    "        params = filename.split('.')[0].split('_')\n",
    "        ex = int(params[0].replace('ex', ''))\n",
    "        core = int(params[1].replace('core', ''))\n",
    "        sp = int(params[2].replace('sp', ''))\n",
    "        arrow = params[3]\n",
    "        w = int(re.findall(r'\\d+', params[4])[0])\n",
    "        kp = int(re.findall(r'\\d+', params[5])[0]) if len(params) > 5 and params[5].endswith('kp') else None\n",
    "        batch = int(re.findall(r'\\d+', params[6])[0]) if len(params) > 6 and params[6].startswith('batch') else 1000\n",
    "        secProcTime = int(re.findall(r'\\d+', params[-1])[0]) if params[-1].endswith('secProcTime') else 5\n",
    "\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        df2 = pd.DataFrame(data)\n",
    "        df2['Executors'] = ex\n",
    "        df2['Cores'] = core\n",
    "        df2['ShufflePartitions'] = sp\n",
    "        df2['Arrow'] = arrow\n",
    "        df2['Workers'] = w\n",
    "        df2['KafkaPartitions'] = kp\n",
    "        df2['Batches'] = batch\n",
    "        df2['Trigger'] = secProcTime\n",
    "\n",
    "        batchId = []\n",
    "        numInputRows = []\n",
    "        inputRowsPerSecond = []\n",
    "        processedRowsPerSecond = []\n",
    "        durationMs = []\n",
    "        numOutputRows = []\n",
    "\n",
    "        for item in data:\n",
    "            try:\n",
    "                batchId.append(item[\"batchId\"])\n",
    "                numInputRows.append(item[\"numInputRows\"])\n",
    "                inputRowsPerSecond.append(item[\"inputRowsPerSecond\"])\n",
    "                processedRowsPerSecond.append(item[\"processedRowsPerSecond\"])\n",
    "                duration_Ms = item[\"durationMs\"][\"triggerExecution\"] / 1000  # convert from ms to s\n",
    "                durationMs.append(duration_Ms)\n",
    "                numOutputRows.append(item[\"sink\"][\"numOutputRows\"])\n",
    "            except Exception as e:\n",
    "                batchID_debug = item[\"batchId\"]\n",
    "                print(f\"Error encountered in batch {batchID_debug}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Check and align the lengths of the arrays\n",
    "        length = max(len(batchId), len(numInputRows), len(inputRowsPerSecond),\n",
    "                     len(processedRowsPerSecond), len(durationMs), len(numOutputRows))\n",
    "\n",
    "        batchId += [np.nan] * (length - len(batchId))\n",
    "        numInputRows += [np.nan] * (length - len(numInputRows))\n",
    "        inputRowsPerSecond += [np.nan] * (length - len(inputRowsPerSecond))\n",
    "        processedRowsPerSecond += [np.nan] * (length - len(processedRowsPerSecond))\n",
    "        durationMs += [np.nan] * (length - len(durationMs))\n",
    "        numOutputRows += [np.nan] * (length - len(numOutputRows))\n",
    "\n",
    "        # Add arrays as columns to the DataFrame\n",
    "        df2['batchId'] = batchId\n",
    "        df2['numInputRows'] = numInputRows\n",
    "        df2['inputRowsPerSecond'] = inputRowsPerSecond\n",
    "        df2['processedRowsPerSecond'] = processedRowsPerSecond\n",
    "        df2['durationMs'] = durationMs\n",
    "        df2['numOutputRows'] = numOutputRows\n",
    "\n",
    "        # Compute message rate\n",
    "        df2['msgrate'] = df2['numInputRows'] / (df2['durationMs'] / 1000)  # Convert duration to seconds\n",
    "\n",
    "        # Drop the unnecessary columns\n",
    "        drop_columns = ['id', 'runId', 'name', 'timestamp', 'stateOperators', 'sources', 'sink', 'numOutputRows']\n",
    "        df2 = df2.drop(drop_columns, axis=1, errors='ignore')\n",
    "\n",
    "        # Append DataFrame to the list\n",
    "        df2_list.append(df2)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "df2 = pd.concat(df2_list, ignore_index=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db451cb2",
   "metadata": {},
   "source": [
    "## Creating the metrics dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6714ac6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m     21\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m---> 22\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[43mlabel\u001b[49m\n\u001b[1;32m     23\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExecutors\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ex\n\u001b[1;32m     24\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCores\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m core\n",
      "\u001b[0;31mNameError\u001b[0m: name 'label' is not defined"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "labels = ['a','b','c','d','e','f','g','h','i','l','m','n','o','p','q','r','s','t','u','v','z']\n",
    "\n",
    "for index, filename in enumerate(os.listdir('./metriche/')):\n",
    "    if filename.endswith('.json'):\n",
    "        params = filename.split('.')[0].split('_')\n",
    "        #label = labels[index % len(labels)]\n",
    "\n",
    "        ex = int(params[0].replace('ex', ''))\n",
    "        core = int(params[1].replace('core', ''))\n",
    "        sp = int(params[2].replace('sp', ''))\n",
    "        arrow = params[3]\n",
    "        w = int(re.findall(r'\\d+', params[4])[0])\n",
    "        kp = int(re.findall(r'\\d+', params[5])[0]) if len(params) > 5 and params[5].endswith('kp') else None\n",
    "        batch = int(re.findall(r'\\d+', params[6])[0]) if len(params) > 6 and params[6].startswith('batch') else 1000\n",
    "        secProcTime = int(re.findall(r'\\d+', params[-1])[0]) if params[-1].endswith('secProcTime') else 5\n",
    "\n",
    "        with open('./metriche/' + filename, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        df['Label']=label\n",
    "        df['Executors'] = ex\n",
    "        df['Cores'] = core\n",
    "        df['ShufflePartitions'] = sp\n",
    "        df['Arrow'] = arrow\n",
    "        df['Workers'] = w\n",
    "        df['KafkaPartitions']=kp\n",
    "        df['Batches'] = batch\n",
    "        df['Trigger'] = secProcTime\n",
    "\n",
    "        batchId = []\n",
    "        numInputRows = []\n",
    "        inputRowsPerSecond = []\n",
    "        processedRowsPerSecond = []\n",
    "        durationMs = []\n",
    "        numOutputRows = []\n",
    "\n",
    "        for item in data:\n",
    "            try:\n",
    "                batchId.append(item[\"batchId\"])\n",
    "                numInputRows.append(item[\"numInputRows\"])\n",
    "                inputRowsPerSecond.append(item[\"inputRowsPerSecond\"])\n",
    "                processedRowsPerSecond.append(item[\"processedRowsPerSecond\"])\n",
    "\n",
    "                duration_Ms = (\n",
    "                     item[\"durationMs\"][\"triggerExecution\"]/1000 #convert from ms to s\n",
    "                )\n",
    "                durationMs.append(duration_Ms)\n",
    "\n",
    "                numOutputRows.append(item[\"sink\"][\"numOutputRows\"])\n",
    "            except Exception as e:\n",
    "                batchID_debug = item[\"batchId\"]\n",
    "                print(f\"Error encountered in batch {batchID_debug}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # Check and align the lengths of the arrays\n",
    "        length = max(len(batchId), len(numInputRows), len(inputRowsPerSecond),\n",
    "                     len(processedRowsPerSecond), len(durationMs), len(numOutputRows))\n",
    "\n",
    "        batchId += [np.nan] * (length - len(batchId))\n",
    "        numInputRows += [np.nan] * (length - len(numInputRows))\n",
    "        inputRowsPerSecond += [np.nan] * (length - len(inputRowsPerSecond))\n",
    "        processedRowsPerSecond += [np.nan] * (length - len(processedRowsPerSecond))\n",
    "        durationMs += [np.nan] * (length - len(durationMs))\n",
    "        numOutputRows += [np.nan] * (length - len(numOutputRows))\n",
    "\n",
    "         # Add arrays as columns to the DataFrame\n",
    "        df['batchId'] = batchId\n",
    "        df['numInputRows'] = numInputRows\n",
    "        df['inputRowsPerSecond'] = inputRowsPerSecond\n",
    "        df['processedRowsPerSecond'] = processedRowsPerSecond\n",
    "        df['durationMs'] = durationMs\n",
    "        df['numOutputRows'] = numOutputRows\n",
    "\n",
    "        # Compute message rate\n",
    "        df['msgrate'] = df['numInputRows'] / (df['durationMs'] / 1000)  # Convert duration to\n",
    "        # Drop the unnecessary columns \n",
    "        drop_columns = ['id', 'runId', 'name', 'timestamp', 'stateOperators', 'sources', 'sink', 'numOutputRows']\n",
    "        df = df.drop(drop_columns, axis=1, errors='ignore')\n",
    "\n",
    "        # Append DataFrame to the list\n",
    "        df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7628b134",
   "metadata": {},
   "source": [
    "## Plot batch processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f8737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing best vs worst configuration\n",
    "#worst config: 10 ex, 1 core, 50 sp, 3 w, 1000 rows/sec, 5 sec of trigger\n",
    "\n",
    "# Plotting the single file\n",
    "batch_durations_best = df1['durationMs']\n",
    "mean_batch_best = batch_durations_best[25:-1].mean()\n",
    "\n",
    "batch_durations_worst = df2['durationMs']\n",
    "mean_batch_worst = batch_durations_worst[25:-1].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4), dpi=500)\n",
    "ax.plot(df1['batchId'], batch_durations_best, label='best_config')\n",
    "ax.plot(df2['batchId'], batch_durations_worst, label='worst_config')\n",
    "\n",
    "ax.set_xlabel('Batch #', fontsize=14)\n",
    "ax.set_ylabel('Batch processing time [s]', fontsize=14)\n",
    "ax.set_title('Best vs Worst Configuration')\n",
    "ax.set_xlim(-1, 210)\n",
    "ax.plot([],[], ' ', label=f'Avg time best={mean_batch_best:1.3f} s')\n",
    "ax.plot([],[], ' ', label=f'Avg time worst={mean_batch_worst:1.3f} s')\n",
    "plt.legend()\n",
    "\n",
    "# Create zoom inset\n",
    "axins = ax.inset_axes([0.21, 0.42, 0.54, 0.30])\n",
    "axins.plot(df1['batchId'][28:82], batch_durations_best[28:82])\n",
    "axins.plot(df2['batchId'][28:82], batch_durations_worst[28:82])\n",
    "axins.set_ylim(1, 9.5)\n",
    "\n",
    "# Add border around the zoom inset\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf67ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc7b8b",
   "metadata": {},
   "source": [
    "## Batch processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ee2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using best configuration: 10 ex, 1 core, 1 sp, aT, 3 w, 10 kp, 5 sec of trigger, 1000 rows/sec\n",
    "\n",
    "target_label_best = 'd'\n",
    "\n",
    "# Filter the DataFrame based on the target label\n",
    "df_target_best = df[df['Label'] == target_label_best]\n",
    "\n",
    "# Plotting the single file\n",
    "batch_durations_best = df_target_best['durationMs']\n",
    "mean_batch_best = batch_durations_best[50:-1].mean()              #restrict the computation to the plateau\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4), dpi=500)\n",
    "ax.plot(df_target_best['batchId'], batch_durations_best)\n",
    "\n",
    "ax.set_xlabel('Batch #', fontsize=14)\n",
    "ax.set_ylabel('Batch processing time [s]', fontsize=14)\n",
    "ax.set_title('Best Configuration')\n",
    "ax.plot([],[], ' ', label=f'Avg time={mean_batch_best:1.3f} s')\n",
    "plt.legend()\n",
    "\n",
    "# Create zoom inset\n",
    "axins = ax.inset_axes([0.33, 0.42, 0.6, 0.35])\n",
    "axins.plot(df_target_best['batchId'][75:200], batch_durations_best[75:200])\n",
    "\n",
    "\n",
    "# Add border around the zoom inset\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872be18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Label']=='n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67cfbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing best vs worst configuration\n",
    "#worst config: 10 ex, 1 core, 50 sp, 3 w, 1000 rows/sec, 5 sec of trigger\n",
    "\n",
    "target_label_best = 'd'\n",
    "target_label_worst = 'n'\n",
    "\n",
    "# Filter the DataFrame based on the target label\n",
    "df_target_best = df[df['Label'] == target_label_best]\n",
    "df_target_worst = df[df['Label'] == target_label_worst]\n",
    "\n",
    "# Plotting the single file\n",
    "batch_durations_best = df_target_best['durationMs']\n",
    "mean_batch_best = batch_durations_best[50:-1].mean()\n",
    "\n",
    "batch_durations_worst = df_target_worst['durationMs']\n",
    "mean_batch_worst = batch_durations_worst[50:-1].mean()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4), dpi=500)\n",
    "ax.plot(df_target_best['batchId'], batch_durations_best, label='best_config')\n",
    "ax.plot(df_target_worst['batchId'], batch_durations_worst, label='worst_config')\n",
    "\n",
    "ax.set_xlabel('Batch #', fontsize=14)\n",
    "ax.set_ylabel('Batch processing time [s]', fontsize=14)\n",
    "ax.set_title('Best vs Worst Configuration')\n",
    "ax.set_xlim(-1, 200)\n",
    "ax.plot([],[], ' ', label=f'Avg time best={mean_batch_best:1.3f} s')\n",
    "ax.plot([],[], ' ', label=f'Avg time worst={mean_batch_worst:1.3f} s')\n",
    "plt.legend()\n",
    "\n",
    "# Create zoom inset\n",
    "axins = ax.inset_axes([0.21, 0.42, 0.54, 0.30])\n",
    "axins.plot(df_target_best['batchId'][25:115], batch_durations_best[25:115])\n",
    "axins.plot(df_target_worst['batchId'][25:115], batch_durations_worst[25:115])\n",
    "axins.set_ylim(1, 7)\n",
    "\n",
    "# Add border around the zoom inset\n",
    "from mpl_toolkits.axes_grid1.inset_locator import mark_inset\n",
    "mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5936e0d",
   "metadata": {},
   "source": [
    "## Input and Processed Rows per Second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c1164",
   "metadata": {},
   "source": [
    "We plot the input and processed rows per second for two settings with different batch size but keeping the rest of the parameters fixed: 10 executors, 1 core, 10 shuffle partition, arrow = True, 3 workers, 10 Kafka partitions, 5 sec of trigger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2946a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(12, 10), dpi=500)\n",
    "\n",
    "#selecting the labels corresponding to 1000 and 5000 rows/s\n",
    "target_label_5000 = 'n'\n",
    "target_label_1000 = 'd'\n",
    "\n",
    "# Filter the DataFrame based on the target label\n",
    "df_target_5000 = df[df['Label'] == target_label_5000]\n",
    "df_target_1000 = df[df['Label'] == target_label_1000]\n",
    "\n",
    "mean_in_1000 = df_target_1000['inputRowsPerSecond'][50:-1].mean()\n",
    "mean_out_1000 = df_target_1000['processedRowsPerSecond'][50:-1].mean()\n",
    "\n",
    "mean_in_5000 = df_target_5000['inputRowsPerSecond'][50:-1].mean()\n",
    "mean_out_5000 = df_target_5000['processedRowsPerSecond'][50:-1].mean()\n",
    "\n",
    "ax[0].plot(df_target_1000['batchId'][0:175], df_target_1000['inputRowsPerSecond'][0:175], color='xkcd:dull blue', label='Input Rows/s')\n",
    "ax[0].plot(df_target_1000['batchId'][0:175], df_target_1000['processedRowsPerSecond'][0:175], color='green', label='Processed Rows/s')\n",
    "ax[0].set_xlabel('Batch #', fontsize=14)\n",
    "ax[0].set_ylabel('rows/s', fontsize=14)\n",
    "ax[0].set_title('1000 rows/s', fontsize=14)  # Set the custom title\n",
    "ax[0].plot([],[], ' ', label=f'Avg input rows={mean_in_1000:1.3f}/s')\n",
    "ax[0].plot([],[], ' ', label=f'Avg processed rows={mean_out_1000:1.3f}/s')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(df_target_5000['batchId'], df_target_5000['inputRowsPerSecond'], color='xkcd:dull blue', label='Input Rows/s')\n",
    "ax[1].plot(df_target_5000['batchId'], df_target_5000['processedRowsPerSecond'], color='green', label='Processed Rows/s')\n",
    "ax[1].set_xlabel('Batch #', fontsize=14)\n",
    "ax[1].set_ylabel('rows/s', fontsize=14)\n",
    "ax[1].set_title('5000 rows/s', fontsize=14)  # Set the custom title\n",
    "ax[1].plot([],[], ' ', label=f'Avg input rows={mean_in_5000:1.3f}/s')\n",
    "ax[1].plot([],[], ' ', label=f'Avg processed rows={mean_out_5000:1.3f}/s')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c135f679",
   "metadata": {},
   "source": [
    "## Box Plot of Duration Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba36d4",
   "metadata": {},
   "source": [
    "We plot the duration time by varying the number of Kafka partitions and keeping the number of shuffle partitions fixed, and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4185ed",
   "metadata": {},
   "source": [
    "### Varying Kafka Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e172b0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the criteria\n",
    "criteria = {\n",
    "    'Executors': 10,\n",
    "    'Cores': 1,\n",
    "    'ShufflePartitions': 10,\n",
    "    'Trigger': 5,\n",
    "    'Workers': 3,\n",
    "    'Arrow': 'aT',\n",
    "    'Batches': 5000\n",
    "}\n",
    "\n",
    "# Convert the 'KafkaPartitions' column to categorical type\n",
    "df['KafkaPartitions'] = df['KafkaPartitions'].astype('category')\n",
    "\n",
    "filtered_df = df[df['KafkaPartitions'] != 6]\n",
    "unique_partitions = filtered_df['KafkaPartitions'].unique()\n",
    "\n",
    "# Create the box plot using seaborn\n",
    "plt.figure(figsize=(12, 8), dpi=500)\n",
    "sns.boxplot(data=filtered_df[50:-1], y=filtered_df['KafkaPartitions'].cat.remove_unused_categories(), x='durationMs', showfliers=False, orient='h')\n",
    "plt.ylabel('Kafka Partition')\n",
    "plt.xlabel('Duration [s]')\n",
    "plt.title('Duration Time per Kafka Partition')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c08676",
   "metadata": {},
   "source": [
    "### Varying Shuffle Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a1e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the criteria\n",
    "criteria = {\n",
    "    'Executors': 10,\n",
    "    'Cores': 1,\n",
    "    'KafkaPartitions': 10,\n",
    "    'Trigger': 5,\n",
    "    'Workers': 3,\n",
    "    'Arrow': 'aT',\n",
    "    'Batches': 5000\n",
    "}\n",
    "\n",
    "# Convert the 'ShufflePartitions' column to categorical type\n",
    "df['ShufflePartitions'] = df['ShufflePartitions'].astype('category')\n",
    "\n",
    "filtered_df = df[df['ShufflePartitions'] != 6]\n",
    "unique_partitions = filtered_df['ShufflePartitions'].unique()\n",
    "\n",
    "# Create the box plot using seaborn\n",
    "plt.figure(figsize=(12, 8), dpi=500)\n",
    "sns.boxplot(data=filtered_df[50:-1], y=filtered_df['ShufflePartitions'].cat.remove_unused_categories(), x='durationMs', showfliers=False, orient='h')\n",
    "plt.ylabel('Shuffle Partition')\n",
    "plt.xlabel('Duration [s]')\n",
    "plt.title('Duration Time per Shuffle Partition')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf15fa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
